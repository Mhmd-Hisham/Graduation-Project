{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_PATH: C:\\Users\\LAPTOP\\Graduation-Project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.vscode',\n",
       " 'chatbot-env',\n",
       " 'DataEngineering',\n",
       " 'FineTuning',\n",
       " 'hierarchy.txt',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'Terminal.ipynb',\n",
       " 'Testing Interface.ipynb',\n",
       " 'Utils',\n",
       " 'WebSocket Interface']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title # Setting up the environment { vertical-output: true, display-mode: \"form\" }\n",
    "\n",
    "###################\n",
    "#####  SETUP  #####\n",
    "###################\n",
    "\n",
    "#@title Setting up project paths\n",
    "import os\n",
    "\n",
    "colab_setup = False #@param {type:\"boolean\"}\n",
    "PROJECT_PATH = \"/content/drive/MyDrive/TWM/Graduation-Project/\" #@param {\"type\":\"string\"}\n",
    "\n",
    "if colab_setup:\n",
    "    from google.colab import drive\n",
    "    print(\"Mounting Google Drive...\", end=\"\", flush=True)\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Done\")\n",
    "\n",
    "else:\n",
    "    # set this to the parent directory of the whole project\n",
    "    PROJECT_PATH = rf\"C:\\Users\\{os.environ['USERNAME']}\\Graduation-Project\"\n",
    "\n",
    "print(\"PROJECT_PATH:\", PROJECT_PATH)\n",
    "os.chdir(PROJECT_PATH)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Mohamed Hisham\n",
      "\n",
      "Github username: Mhmd-Hisham\n",
      "\n",
      "Email: Mohamed00Hisham@gmail.com\n",
      "\n",
      "Last updated: 2022-10-16T05:38:32.890313+02:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.5\n",
      "IPython version      : 8.5.0\n",
      "\n",
      "Compiler    : MSC v.1928 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 165 Stepping 2, GenuineIntel\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "sys: 3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title # Environment Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Mohamed Hisham\" --email \"Mohamed00Hisham@gmail.com\" --github_username \"Mhmd-Hisham\"\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.EasyT5 as EasyT5\n",
    "import multiprocessing\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5TokenizerFast as T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"DataEngineering/FinalDataset/large/\" #@param {\"type\": \"string\"}\n",
    "MODEL_CHECKPOINTS = \"FineTuning/T5/checkpoints/\" #@param {\"type\": \"string\"}\n",
    "TENSORBOARD_LOGS = \"FineTuning/T5/TB_LOGS/\" #@param {\"type\":\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = EasyT5.ExperimentParameters()\n",
    "\n",
    "SEED = 512\n",
    "\n",
    "# parameters related to the training process\n",
    "# and the PyTorch Lightning trainer\n",
    "parameters['trainer'] = {\n",
    "    # saves the last recent 'n' epochs\n",
    "    \"save_last_n_epochs\": 3,\n",
    "    # the fixed learning rate for the model\n",
    "    \"fixed_learning_rate\": 1e-4,\n",
    "    # the monitor of the early stopping\n",
    "    \"early_stopping_monitor\": \"val_loss\",\n",
    "    # the minimum delta between the epochs to apply early stopping\n",
    "    \"early_stopping_min_delta\": 0.01,\n",
    "    # 0 to disable early stopping feature\n",
    "    \"early_stopping_patience_epochs\": 0,\n",
    "    # the mode of the early stopping criteria\n",
    "    \"early_stopping_mode\": \"min\",\n",
    "    # the maximum number of epochs to train/fine-tune the model on\n",
    "    \"max_epochs\": 5,\n",
    "    # the floating point numbers precision\n",
    "    \"precision\": 32,\n",
    "    # the training batch size \n",
    "    # the batch size at which the data is loaded into memory\n",
    "    \"batch_size\": 8,\n",
    "}\n",
    "\n",
    "# general parameters about the working environment\n",
    "parameters['general'] = {\n",
    "    # the output directory\n",
    "    \"output_dir\":\"\",\n",
    "    # the name/path of the checkpoint to be loaded from Hugging face\n",
    "    # or from the local disk\n",
    "    \"checkpoint_name\": MODEL_CHECKPOINTS+\"-epoch-9-tloss-1.5577-vloss-1.8296\",\n",
    "    # the name that will appear on tensorboard\n",
    "    \"tensorboard_name\": \"t5-v1_1-base_BatchSize-16_N-Splits-4_DatasetSize-large_Topic-Food&Drink_version_2\",\n",
    "    # the number of cpu cores in the current machine\n",
    "    \"cpu_cores\": multiprocessing.cpu_count(),\n",
    "    # the environment seed\n",
    "    'seed':SEED,\n",
    "}\n",
    "\n",
    "# the parameters passed to the tokenizer when encoding text\n",
    "parameters['encoder'] = {\n",
    "    # the padding method for the input sequences\n",
    "    \"padding\":\"max_length\",\n",
    "    # whether to truncate long sequences or not\n",
    "    \"truncation\":True,\n",
    "    # whether to add special tokens in the input sequences or not\n",
    "    \"add_special_tokens\": True,\n",
    "    # the maximum length of the input sequence\n",
    "    \"max_length\": 512,\n",
    "}\n",
    "\n",
    "# the parameters passed to the model when generating text\n",
    "parameters['generator'] = {\n",
    "    # the number of beams used in the beam search (also known as beam width)\n",
    "    \"num_beams\": 2,\n",
    "    # the maximum length of the generated sequences\n",
    "    \"max_length\": 512,\n",
    "    # the repetition penalty added when the model repeats words\n",
    "    \"repetition_penalty\": 2.5,\n",
    "    # the penalty aded when the model generates lengthly sequences\n",
    "    \"length_penalty\": 1.0,\n",
    "    # whether to stop the beam search when at least `num_beams` sentences are finished per batch or not.\n",
    "    \"early_stopping\": True,\n",
    "    # if set to float < 1, only the most probable tokens with probabilities that add up to `top_p` or higher are kept for generation.\n",
    "    \"top_p\": 0.95,\n",
    "    # the number of highest probability vocabulary tokens to keep for top-k-filtering.\n",
    "    \"top_k\": 50,\n",
    "    # the number of returned sequences\n",
    "    \"num_return_sequences\": 1,\n",
    "    # whether to skip special tokens when generating or not\n",
    "    \"skip_special_tokens\": True,\n",
    "    # whether to clean all tokenization spaces before returning the output or not\n",
    "    \"clean_up_tokenization_spaces\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['general'][\"checkpoint_name\"] = os.path.join(\n",
    "    PROJECT_PATH,\n",
    "    MODEL_CHECKPOINTS,\n",
    "    \"-epoch-9-tloss-1.5577-vloss-1.8296\"\n",
    ")\n",
    "parameters['general'][\"tensorboard_name\"] = \"t5-v1_1-base_BatchSize-16_N-Splits-4_DatasetSize-large_Topic-Food&Drink_version_2\",\n",
    "\n",
    "# load the model\n",
    "model = EasyT5.EasyT5(parameters)\n",
    "model.from_pretrained(T5Tokenizer, T5ForConditionalGeneration, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a pizza.', 'a pizza. What kind of food?', 'a pizza with my friends.']\n"
     ]
    }
   ],
   "source": [
    "# you can experiment with different generator parameters like this\n",
    "custom_parameters = parameters.copy()\n",
    "\n",
    "# custom_parameters['generator']['max_length'] = \n",
    "# custom_parameters['generator']['repetition_penalty'] = \n",
    "# custom_parameters['generator']['length_penalty'] = \n",
    "# custom_parameters['generator']['early_stopping'] = \n",
    "custom_parameters['generator']['num_beams'] = 3\n",
    "custom_parameters['generator']['top_p'] = 0.95\n",
    "custom_parameters['generator']['top_k'] = 100\n",
    "custom_parameters['generator']['num_return_sequences'] = 3\n",
    "\n",
    "suggestion = model.predict(\"complete: I want to eat \", custom_parameters)\n",
    "print(suggestion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('chatbot-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03d17e92b9af9393008ccb7443bbe96b4789aebfc0fb054f8d2c26b133cdc647"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
