{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing Interface.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1lU-TpzTcKGIvYrtJGWHXPi4P9eSt9M17","authorship_tag":"ABX9TyMsEtTooLlaNd7wJxYg/zex"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5b062a5f40e346ec9c81283367f834ff":{"model_module":"@jupyter-widgets/controls","model_name":"GridBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"GridBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"GridBoxView","box_style":"","children":["IPY_MODEL_ae9f2423cdf945febd842e0881c904eb","IPY_MODEL_43bdafacc1c641c1954c18aa0c9f8fcf","IPY_MODEL_85ee7d005e4e48f9ba2777a3fc261a29","IPY_MODEL_36df6ed034fb430b86dc882ff789b8f3","IPY_MODEL_1d04fad5b74d40968591f5f5d74c1b78","IPY_MODEL_638cf2391d74456289a8d266c4d7cdc1","IPY_MODEL_c64606327c314de889a5ceee8aaa96a7","IPY_MODEL_01c56af383d1481898ee09de169cd341"],"layout":"IPY_MODEL_1fc33ec8d9b14733a67620fe3d4d5c8d"}},"ae9f2423cdf945febd842e0881c904eb":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a83f3f88fa0841b78c8377769e7e4e20","placeholder":"​","style":"IPY_MODEL_581f6d7a8c544ccca9d761eeb99a133e","value":""}},"43bdafacc1c641c1954c18aa0c9f8fcf":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Reset","disabled":false,"icon":"","layout":"IPY_MODEL_a1de34802319471d9f492299865486b2","style":"IPY_MODEL_a8276aff44e54781aa8b0e5ba363368d","tooltip":""}},"85ee7d005e4e48f9ba2777a3fc261a29":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_732338c3057d49e9ac0b644dded59cae","placeholder":"​","style":"IPY_MODEL_c616f2cdd614424fb6e807ee65783a8f","value":"Context:"}},"36df6ed034fb430b86dc882ff789b8f3":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_06d2137dab7d485da278f1b10cb16ad6","placeholder":"​","rows":1,"style":"IPY_MODEL_5cc5e69ce9a24f928ec1ba065c3de2e2","value":""}},"1d04fad5b74d40968591f5f5d74c1b78":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58ed4984875d4a35b5c193cd6bebeb08","placeholder":"​","style":"IPY_MODEL_67a9a61f64c04001abf09cf3214fd538","value":"History:"}},"638cf2391d74456289a8d266c4d7cdc1":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"","description_tooltip":null,"disabled":true,"layout":"IPY_MODEL_5339c6661ea44683a3e7213438080d26","placeholder":"previous messages will appear here..","rows":10,"style":"IPY_MODEL_93cd795979d34e11b7cf02ac486a2ffe","value":""}},"c64606327c314de889a5ceee8aaa96a7":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dedb64e25b94ac1a24424f70adeefaa","placeholder":"​","style":"IPY_MODEL_379bcc8e6a2c4beebbd79138940c8590","value":"Response:"}},"01c56af383d1481898ee09de169cd341":{"model_module":"@jupyter-widgets/controls","model_name":"ComboboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ComboboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ComboboxView","continuous_update":true,"description":"","description_tooltip":null,"disabled":false,"ensure_option":false,"layout":"IPY_MODEL_8806babcff984d728047157678ab49ab","options":[],"placeholder":"Enter your message here","style":"IPY_MODEL_db896375761c49feb6dddd038a56524d","value":"i "}},"1fc33ec8d9b14733a67620fe3d4d5c8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":"repeat(2, 100px)","grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a83f3f88fa0841b78c8377769e7e4e20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"581f6d7a8c544ccca9d761eeb99a133e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1de34802319471d9f492299865486b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8276aff44e54781aa8b0e5ba363368d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"732338c3057d49e9ac0b644dded59cae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c616f2cdd614424fb6e807ee65783a8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06d2137dab7d485da278f1b10cb16ad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc5e69ce9a24f928ec1ba065c3de2e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58ed4984875d4a35b5c193cd6bebeb08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67a9a61f64c04001abf09cf3214fd538":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5339c6661ea44683a3e7213438080d26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93cd795979d34e11b7cf02ac486a2ffe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dedb64e25b94ac1a24424f70adeefaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"379bcc8e6a2c4beebbd79138940c8590":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8806babcff984d728047157678ab49ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db896375761c49feb6dddd038a56524d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["#@title # Setting up the environment { vertical-output: true, display-mode: \"form\" }\n","\n","###################\n","#####  SETUP  #####\n","###################\n","\n","print(\"Mounting google drive.. \")\n","# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)\n","\n","# setting the project path\n","PROJECT_PATH = \"./\" #@param {type:\"string\"}\n","\n","print(\"Navigating to the project folder.. \")\n","import os\n","os.chdir(PROJECT_PATH)\n","\n","print(\"Installing dependencies... \")\n","# !pip install -q sentencepiece\n","# !pip install -q torch>=1.7.0,!=1.8.0\n","# !pip install -q transformers==4.16.2\n","# !pip install -q pytorch-lightning==1.5.10\n","# !pip install -q swifter \n","# !pip install -q evaluate \n","# !pip install -q bert-score \n","\n","print(\"Found the following files:\", os.listdir())\n","\n","\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","# import Utils.helperFunctions as helperFunctions\n","# import Utils.dialogue_utils as dialogue_utils\n","\n","###################\n","##### CONFIGS #####\n","###################\n","\n","import random\n","import torch\n","\n","\n","\n","print(\"Runtime info:- \")\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"Y_GYY1HLj5oI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657207331052,"user_tz":-120,"elapsed":7389,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"e1529ada-789c-4209-8ae7-9b9562220f44"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting google drive.. \n","Navigating to the project folder.. \n","Installing dependencies... \n","Found the following files: ['.ipynb_checkpoints', 'Book', 'cuda_path.txt', 'google_drive_local_runtime_cc.bat', 'Graduation-Project', 'Old', 'speech-to-text', 'streamlit_interface.py', 'T5 Checkpoints', 't5_on_tpu.ipynb']\n","Runtime info:- \n","Thu Jul  7 17:22:10 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n","| N/A   59C    P8    10W /  N/A |   1659MiB /  6144MiB |     22%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A       708    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n","|    0   N/A  N/A      3676    C+G   ...\\app-1.0.9005\\Discord.exe    N/A      |\n","|    0   N/A  N/A      6480    C+G   ...4__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n","|    0   N/A  N/A      7864    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A      9456    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n","|    0   N/A  N/A      9768    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n","|    0   N/A  N/A      9848    C+G   ...0.0.2.0\\GoogleDriveFS.exe    N/A      |\n","|    0   N/A  N/A     11640    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A     13984    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n","|    0   N/A  N/A     14108    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n","|    0   N/A  N/A     16300    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n","|    0   N/A  N/A     16784    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A     17076    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     19380    C+G   ...ge\\Application\\msedge.exe    N/A      |\n","|    0   N/A  N/A     20712    C+G                                   N/A      |\n","|    0   N/A  N/A     20760    C+G   ...wekyb3d8bbwe\\Music.UI.exe    N/A      |\n","|    0   N/A  N/A     21944    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     23212    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n","|    0   N/A  N/A     23484    C+G   ...\\app-1.0.9005\\Discord.exe    N/A      |\n","|    0   N/A  N/A     24120    C+G   ..._dt26b99r8h8gj\\RtkUWP.exe    N/A      |\n","|    0   N/A  N/A     26668    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n","|    0   N/A  N/A     27644    C+G   ...4__8wekyb3d8bbwe\\Time.exe    N/A      |\n","|    0   N/A  N/A     28420    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n","|    0   N/A  N/A     28812    C+G   ...artMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     29272    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"KOyaCf5PpzRP"},"source":["# Code Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"DjdwQwl3px8f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657207334750,"user_tz":-120,"elapsed":3693,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"3de18b1f-29fe-4a3b-fcd4-8a6a57ae7e0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting the project seed.. \n","Done\n"]}],"source":["#@title Imports\n","\n","import os\n","import re\n","import gc\n","import time\n","import glob\n","import random\n","import functools\n","import multiprocessing\n","from typing import List, Tuple, Dict, Callable\n","\n","# parallize the apply function of pandas\n","# import swifter\n","\n","# to show the full dialogues in the dataframes\n","import pandas as pd\n","pd.set_option('max_colwidth', 1000)\n","\n","# import spacy\n","\n","import torch\n","import numpy as np\n","\n","from transformers import (\n","    T5ForConditionalGeneration,\n","    PreTrainedTokenizer,\n","    T5TokenizerFast as T5Tokenizer,\n",")\n","\n","\n","\n","from torch.optim import AdamW\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoModelWithLMHead, AutoTokenizer\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks.progress import TQDMProgressBar\n","\n","import matplotlib.pyplot as plt\n","\n","plt.style.use(\"seaborn\")\n","SEED = 512 #@param {type:\"integer\"}\n","\n","def reset_environment(reset_seed=True, seed=SEED):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    if reset_seed:\n","        pl.seed_everything(SEED, workers=True)\n","\n","print(\"Setting the project seed.. \")\n","def seed_everything(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","def reset_environment(reset_seed=True, seed=SEED):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    if reset_seed:\n","        pl.seed_everything(SEED, workers=True)\n","\n","seed_everything()\n","\n","print(\"Done\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"ljOISLdFwVOe","executionInfo":{"status":"ok","timestamp":1657207334808,"user_tz":-120,"elapsed":49,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}}},"outputs":[],"source":["#@title PytorchDataset\n","class PyTorchDataset(Dataset):\n","    \"\"\"  PyTorch Dataset class  \"\"\"\n","    def __init__(\n","        self,\n","        data: pd.DataFrame,\n","        tokenizer: PreTrainedTokenizer,\n","        source_max_token_len: int = 512,\n","        target_max_token_len: int = 512,\n","    ):\n","        \"\"\"\n","        initiates a PyTorch Dataset Module for input data\n","        Args:\n","            data (pd.DataFrame): input pandas dataframe. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n","            tokenizer (PreTrainedTokenizer): a PreTrainedTokenizer (T5Tokenizer, MT5Tokenizer, or ByT5Tokenizer)\n","            source_max_token_len (int, optional): max token length of source text. Defaults to 512.\n","            target_max_token_len (int, optional): max token length of target text. Defaults to 512.\n","        \"\"\"\n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.source_max_token_len = source_max_token_len\n","        self.target_max_token_len = target_max_token_len\n","\n","    def __len__(self):\n","        \"\"\" returns length of data \"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, index: int):\n","        \"\"\" returns dictionary of input tensors to feed into T5/MT5 model\"\"\"\n","\n","        data_row = self.data.iloc[index]\n","        source_text = data_row[\"source_text\"]\n","\n","        source_text_encoding = self.tokenizer(\n","            source_text,\n","            max_length=self.source_max_token_len,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_attention_mask=True,\n","            add_special_tokens=True,\n","            return_tensors=\"pt\",\n","        )\n","\n","        target_text_encoding = self.tokenizer(\n","            data_row[\"target_text\"],\n","            max_length=self.target_max_token_len,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_attention_mask=True,\n","            add_special_tokens=True,\n","            return_tensors=\"pt\",\n","        )\n","\n","        labels = target_text_encoding[\"input_ids\"]\n","        # to make sure we have correct labels for T5 text generation\n","        labels[labels == 0] = -100\n","\n","        return {\n","            \"source_text_input_ids\": source_text_encoding[\"input_ids\"].flatten(),\n","            \"source_text_attention_mask\": source_text_encoding[\"attention_mask\"].flatten(),\n","            \"labels\": labels.flatten(),\n","            \"labels_attention_mask\": target_text_encoding[\"attention_mask\"].flatten(),\n","        }"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"brYCNJm4wkI3","executionInfo":{"status":"ok","timestamp":1657207334826,"user_tz":-120,"elapsed":14,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}}},"outputs":[],"source":["#@title LightningDataModule\n","class LightningDataModule(pl.LightningDataModule):\n","    \"\"\" PyTorch Lightning data class \"\"\"\n","\n","    def __init__(\n","        self,\n","        train_df: pd.DataFrame,\n","        test_df: pd.DataFrame,\n","        eval_df: pd.DataFrame,\n","        tokenizer: PreTrainedTokenizer,\n","        batch_size: int = 4,\n","        source_max_token_len: int = 512,\n","        target_max_token_len: int = 512,\n","        num_workers: int = 2,\n","    ):\n","        \"\"\"\n","        initiates a PyTorch Lightning Data Module\n","        Args:\n","            train_df (pd.DataFrame): training dataframe. Dataframe must contain 2 columns --> \"source_text\" & \"target_text\"\n","            test_df (pd.DataFrame): validation dataframe. Dataframe must contain 2 columns --> \"source_text\" & \"target_text\"\n","            tokenizer (PreTrainedTokenizer): PreTrainedTokenizer (T5Tokenizer, MT5Tokenizer, or ByT5Tokenizer)\n","            batch_size (int, optional): batch size. Defaults to 4.\n","            source_max_token_len (int, optional): max token length of source text. Defaults to 512.\n","            target_max_token_len (int, optional): max token length of target text. Defaults to 512.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.train_df = train_df\n","        self.test_df = test_df\n","        self.eval_df = eval_df\n","        self.batch_size = batch_size\n","        self.tokenizer = tokenizer\n","        self.source_max_token_len = source_max_token_len\n","        self.target_max_token_len = target_max_token_len\n","        self.num_workers = num_workers\n","\n","    def setup(self, stage=None):\n","        self.train_dataset = PyTorchDataset(\n","            self.train_df,\n","            self.tokenizer,\n","            self.source_max_token_len,\n","            self.target_max_token_len,\n","        )\n","        self.test_dataset = PyTorchDataset(\n","            self.test_df,\n","            self.tokenizer,\n","            self.source_max_token_len,\n","            self.target_max_token_len,\n","        )\n","        self.val_dataset = PyTorchDataset(\n","            self.eval_df,\n","            self.tokenizer,\n","            self.source_max_token_len,\n","            self.target_max_token_len,\n","        )\n","\n","    def train_dataloader(self):\n","        \"\"\" training dataloader \"\"\"\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=self.num_workers,\n","        )\n","\n","    def test_dataloader(self):\n","        \"\"\" test dataloader \"\"\"\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers,\n","        )\n","\n","    def val_dataloader(self):\n","        \"\"\" validation dataloader \"\"\"\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers,\n","        )\n"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","id":"d1_xKDfqxXBk","executionInfo":{"status":"ok","timestamp":1657207334845,"user_tz":-120,"elapsed":13,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}}},"outputs":[],"source":["# @title LightningModel\n","\n","class LightningModel(pl.LightningModule):\n","    \"\"\" PyTorch Lightning Model class\"\"\"\n","\n","    def __init__(\n","        self,\n","        tokenizer,\n","        model,\n","        checkpoint_name: str,\n","        output_dir: str,\n","        save_only_last_epoch: bool = False,\n","        learning_rate: float = 0.0001,\n","    ):\n","        \"\"\"\n","        initiates a PyTorch Lightning Model\n","        Args:\n","            tokenizer : T5/MT5/ByT5 tokenizer\n","            model : T5/MT5/ByT5 model\n","            output_dir (str, optional): output directory to save model checkpoints. Defaults to \"outputs\".\n","            save_only_last_epoch (bool, optional): If True, save just the last epoch else models are saved for every epoch\n","        \"\"\"\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.output_dir = output_dir\n","        self.average_training_loss = None\n","        self.average_validation_loss = None\n","        self.save_only_last_epoch = save_only_last_epoch\n","        self.learning_rate = learning_rate\n","        self.checkpoint_name = checkpoint_name\n","\n","        self.checkpoints_dir = f\"{self.output_dir}/{self.checkpoint_name}/\"\n","\n","        self.experiment_version = list(\n","            sorted(map(lambda s: int(s[s.rfind('version')+8:]),\n","                   ['version_-1']+glob.glob(self.checkpoints_dir+\"/version_*\")),\n","                   reverse=True)\n","            )[0]+1\n","\n","        self.checkpoints_dir += f\"version_{self.experiment_version}/\"\n","\n","    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n","        \"\"\" forward step \"\"\"\n","        output = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            labels=labels,\n","            decoder_attention_mask=decoder_attention_mask,\n","        )\n","\n","        return output.loss, output.logits\n","\n","    def training_step(self, batch, batch_size):\n","        \"\"\" training step \"\"\"\n","        input_ids = batch[\"source_text_input_ids\"]\n","        attention_mask = batch[\"source_text_attention_mask\"]\n","        labels = batch[\"labels\"]\n","        labels_attention_mask = batch[\"labels_attention_mask\"]\n","\n","        loss, outputs = self(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            decoder_attention_mask=labels_attention_mask,\n","            labels=labels,\n","        )\n","\n","        self.log(\n","            \"train_loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True\n","        )\n","        return loss\n","\n","    def validation_step(self, batch, batch_size):\n","        \"\"\" validation step \"\"\"\n","        input_ids = batch[\"source_text_input_ids\"]\n","        attention_mask = batch[\"source_text_attention_mask\"]\n","        labels = batch[\"labels\"]\n","        labels_attention_mask = batch[\"labels_attention_mask\"]\n","\n","        loss, outputs = self(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            decoder_attention_mask=labels_attention_mask,\n","            labels=labels,\n","        )\n","\n","        self.log(\n","            \"val_loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True\n","        )\n","        return loss\n","\n","    def test_step(self, batch, batch_size):\n","        \"\"\" test step \"\"\"\n","        input_ids = batch[\"source_text_input_ids\"]\n","        attention_mask = batch[\"source_text_attention_mask\"]\n","        labels = batch[\"labels\"]\n","        labels_attention_mask = batch[\"labels_attention_mask\"]\n","\n","        loss, outputs = self(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            decoder_attention_mask=labels_attention_mask,\n","            labels=labels,\n","        )\n","\n","        self.log(\"test_loss\", loss, prog_bar=True, logger=True,)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        \"\"\" configure optimizers \"\"\"\n","\n","        # return Adafactor(\n","        #     self.parameters(),\n","        #     lr=1e-3,\n","        #     eps=(1e-30, 1e-3),\n","        #     clip_threshold=1.0,\n","        #     decay_rate=-0.8,\n","        #     beta1=None,\n","        #     weight_decay=0.0,\n","        #     relative_step=False,\n","        #     scale_parameter=False,\n","        #     warmup_init=False\n","        # )\n","\n","        # this is the old optimizer\n","        return AdamW(\n","            self.parameters(), \n","            lr=self.learning_rate\n","        )\n","\n","    def training_epoch_end(self, training_step_outputs):\n","        \"\"\" save tokenizer and model on epoch end \"\"\"\n","        self.average_training_loss = np.round(\n","            torch.mean(torch.stack([x[\"loss\"] for x in training_step_outputs])).item(),\n","            4,\n","        )\n","        path = self.checkpoints_dir \\\n","              +f\"-epoch-{self.current_epoch}\" \\\n","              +f\"-tloss-{str(self.average_training_loss)}\" \\\n","              +f\"-vloss-{str(self.average_validation_loss)}\"\n","        \n","        if self.save_only_last_epoch:\n","            if self.current_epoch == self.trainer.max_epochs - 1:\n","                self.tokenizer.save_pretrained(path)\n","                self.model.save_pretrained(path)\n","        else:\n","            self.tokenizer.save_pretrained(path)\n","            self.model.save_pretrained(path)\n","\n","    def validation_epoch_end(self, validation_step_outputs):\n","        _loss = [x.cpu() for x in validation_step_outputs]\n","        self.average_validation_loss = np.round(\n","            torch.mean(torch.stack(_loss)).item(),\n","            4,\n","        )\n"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","id":"tqZI6zEUnLEG","executionInfo":{"status":"ok","timestamp":1657207334896,"user_tz":-120,"elapsed":48,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}}},"outputs":[],"source":["#@title SimpleT5 class\n","class SimpleT5:\n","    \"\"\" Custom SimpleT5 class \"\"\"\n","\n","    def __init__(self,\n","        checkpoint_name: str,\n","        output_dir: str,\n","        learning_rate: float,\n","    ) -> None:\n","        \"\"\" initiates SimpleT5 class \"\"\"\n","        self.learning_rate = learning_rate\n","        self.output_dir = output_dir\n","        self.checkpoint_name = checkpoint_name\n","        self.trainer = None\n","        self.callbacks = [TQDMProgressBar(refresh_rate=5)]\n","\n","    def from_pretrained(self, model_name=\"t5-small\") -> None:\n","        \"\"\"\n","        loads T5/MT5 Model model for training/finetuning\n","        Args:\n","            model_name (str, optional): exact model architecture name, \"t5-base\" or \"t5-large\". Defaults to \"t5-base\".\n","        \"\"\"\n","        self.tokenizer = T5Tokenizer.from_pretrained(f\"{model_name}\")\n","        self.model = T5ForConditionalGeneration.from_pretrained(\n","            f\"{model_name}\", return_dict=True\n","        )\n","\n","    def train(\n","        self,\n","        train_df: pd.DataFrame,\n","        test_df: pd.DataFrame,\n","        eval_df: pd.DataFrame,\n","        source_max_token_len: int = 512,\n","        target_max_token_len: int = 512,\n","        batch_size: int = 8,\n","        max_epochs: int = 5,\n","        use_gpu: bool = True,\n","        early_stopping_patience_epochs: int = 0,  # 0 to disable early stopping feature\n","        precision=32,\n","        logger=\"default\",\n","        dataloader_num_workers: int = 2,\n","        save_only_last_epoch: bool = False,\n","    ):\n","        \"\"\"\n","        trains T5/MT5 model on custom dataset\n","        Args:\n","            train_df (pd.DataFrame): training datarame. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n","            test_df ([type], optional): test datarame. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n","            eval_df ([type], optional): validation datarame. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n","            source_max_token_len (int, optional): max token length of source text. Defaults to 512.\n","            target_max_token_len (int, optional): max token length of target text. Defaults to 512.\n","            batch_size (int, optional): batch size. Defaults to 8.\n","            max_epochs (int, optional): max number of epochs. Defaults to 5.\n","            use_gpu (bool, optional): if True, model uses gpu for training. Defaults to True.\n","            output_dir (str, optional): output directory to save model checkpoints. Defaults to \"outputs\".\n","            early_stopping_patience_epochs (int, optional): monitors val_loss on epoch end and stops training, if val_loss does not improve after the specied number of epochs. set 0 to disable early stopping. Defaults to 0 (disabled)\n","            precision (int, optional): sets precision training - Double precision (64), full precision (32) or half precision (16). Defaults to 32.\n","            logger (pytorch_lightning.loggers) : any logger supported by PyTorch Lightning. Defaults to \"default\". If \"default\", pytorch lightning default logger is used.\n","            dataloader_num_workers (int, optional): number of workers in train/test/val dataloader\n","            save_only_last_epoch (bool, optional): If True, saves only the last epoch else models are saved at every epoch\n","        \"\"\"\n","        self.data_module = LightningDataModule(\n","            train_df,\n","            test_df,\n","            eval_df,\n","            self.tokenizer,\n","            batch_size=batch_size,\n","            source_max_token_len=source_max_token_len,\n","            target_max_token_len=target_max_token_len,\n","            num_workers=dataloader_num_workers,\n","        )\n","\n","        self.T5Model = LightningModel(\n","            tokenizer=self.tokenizer,\n","            model=self.model,\n","            checkpoint_name=self.checkpoint_name,\n","            output_dir=self.output_dir,\n","            save_only_last_epoch=save_only_last_epoch,\n","        )\n","\n","        # add callbacks for early stopping\n","        if early_stopping_patience_epochs > 0:\n","            early_stop_callback = EarlyStopping(\n","                monitor=\"val_loss\",\n","                min_delta=0.01,\n","                patience=early_stopping_patience_epochs,\n","                verbose=True,\n","                mode=\"min\",\n","            )\n","            self.callbacks.append(early_stop_callback)\n","\n","        # add gpu support\n","        gpus = 1 if use_gpu else 0\n","\n","        # add logger\n","        loggers = True if logger == \"default\" else logger\n","\n","        # prepare trainer\n","        self.trainer = pl.Trainer(\n","            logger=loggers,\n","            callbacks=self.callbacks,\n","            max_epochs=max_epochs,\n","            gpus=gpus,\n","            precision=precision,\n","            log_every_n_steps=1,\n","        )\n","\n","        # fit trainer\n","        self.trainer.fit(self.T5Model, self.data_module)\n","\n","    def load_model(\n","        self,\n","        model_dir: str = \"outputs\",\n","        use_gpu: bool = False,\n","        ):\n","        \"\"\"\n","        loads a checkpoint for inferencing/prediction\n","        Args:\n","            model_dir (str, optional): path to model directory. Defaults to \"outputs\".\n","            use_gpu (bool, optional): if True, model uses gpu for inferencing/prediction. Defaults to True.\n","        \"\"\"\n","        self.model = T5ForConditionalGeneration.from_pretrained(f\"{model_dir}\")\n","        self.tokenizer = T5Tokenizer.from_pretrained(f\"{model_dir}\")\n","\n","        if use_gpu:\n","            if torch.cuda.is_available():\n","                self.device = torch.device(\"cuda\")\n","            else:\n","                raise \"exception ---> no gpu found. set use_gpu=False, to use CPU\"\n","        else:\n","            self.device = torch.device(\"cpu\")\n","\n","        self.model = self.model.to(self.device)\n","\n","    def predict(\n","        self,\n","        source_text: str,\n","        max_length: int = 512,\n","        num_return_sequences: int = 1,\n","        num_beams: int = 2,\n","        top_k: int = 50,\n","        top_p: float = 0.95,\n","        do_sample: bool = True,\n","        repetition_penalty: float = 2.5,\n","        length_penalty: float = 1.0,\n","        early_stopping: bool = True,\n","        temperature: float=1.0,\n","        skip_special_tokens: bool = True,\n","        clean_up_tokenization_spaces: bool = True,\n","    ):\n","        \"\"\"\n","        generates prediction for T5/MT5 model\n","        Args:\n","            source_text (str): any text for generating predictions\n","            max_length (int, optional): max token length of prediction. Defaults to 512.\n","            num_return_sequences (int, optional): number of predictions to be returned. Defaults to 1.\n","            num_beams (int, optional): number of beams. Defaults to 2.\n","            top_k (int, optional): Defaults to 50.\n","            top_p (float, optional): Defaults to 0.95.\n","            do_sample (bool, optional): Defaults to True.\n","            repetition_penalty (float, optional): Defaults to 2.5.\n","            length_penalty (float, optional): Defaults to 1.0.\n","            early_stopping (bool, optional): Defaults to True.\n","            skip_special_tokens (bool, optional): Defaults to True.\n","            clean_up_tokenization_spaces (bool, optional): Defaults to True.\n","        Returns:\n","            list[str]: returns predictions\n","        \"\"\"\n","        input_ids = self.tokenizer.encode(\n","            source_text, return_tensors=\"pt\", add_special_tokens=True\n","        )\n","        input_ids = input_ids.to(self.device)\n","        output = self.model.generate(\n","            input_ids=input_ids,\n","            num_beams=num_beams,\n","            max_length=max_length,\n","            repetition_penalty=repetition_penalty,\n","            length_penalty=length_penalty,\n","            early_stopping=early_stopping,\n","            top_p=top_p,\n","            top_k=top_k,\n","            num_return_sequences=num_return_sequences,\n","            return_dict_in_generate=True,\n","            output_scores=True,\n","        )\n","            # forced_eos_token_id=self.tokenizer.eos_token\n","        generated_ids = output['sequences']\n","        preds = [\n","            self.tokenizer.decode(\n","                g,\n","                skip_special_tokens=skip_special_tokens,\n","                clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n","            )\n","            for g in generated_ids\n","        ]\n","        return preds, output['sequences_scores']\n","\n","    def predict_multiple(\n","        self,\n","        source_text: List[str],\n","        max_length: int = 256,\n","        num_return_sequences: int = 1,\n","        num_beams: int = 2,\n","        top_k: int = 50,\n","        top_p: float = 0.95,\n","        do_sample: bool = True,\n","        repetition_penalty: float = 2.5,\n","        length_penalty: float = 1.0,\n","        early_stopping: bool = True,\n","        skip_special_tokens: bool = True,\n","        clean_up_tokenization_spaces: bool = True,\n","    ):\n","        input_ids = self.tokenizer(\n","            source_text, \n","            return_tensors=\"pt\",\n","            add_special_tokens=True,\n","            padding='max_length',\n","            max_length=max_length,\n","            truncation=True\n","        )['input_ids']\n","\n","        input_ids = input_ids.to(self.device)\n","\n","        generated_samples = self.model.generate(\n","            input_ids=input_ids,\n","            num_beams=num_beams,\n","            max_length=max_length,\n","            repetition_penalty=repetition_penalty,\n","            length_penalty=length_penalty,\n","            early_stopping=early_stopping,\n","            top_p=top_p,\n","            top_k=top_k,\n","            num_return_sequences=num_return_sequences,\n","        )\n","\n","        return [self.tokenizer.decode(\n","                g, \n","                skip_special_tokens=skip_special_tokens, \n","                clean_up_tokenization_spaces=clean_up_tokenization_spaces) \n","            for g in generated_samples\n","        ]\n","\n","    def batch_predict(self, batch_size: int, sequences: List[str], **kwargs):\n","        output = []\n","        n_steps = (len(sequences)//batch_size)\n","        for i in range(0, n_steps*batch_size, batch_size):\n","            output += self.predict_multiple(\n","                sequences[i:i+batch_size], \n","                **kwargs)\n","        output += self.predict_multiple(\n","          sequences[n_steps*batch_size:], \n","          **kwargs\n","        )\n","        return output"]},{"cell_type":"code","source":["from colorama import Style, Back, Fore"],"metadata":{"id":"VG35ltyL6l1A","executionInfo":{"status":"ok","timestamp":1657207334901,"user_tz":-120,"elapsed":1,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#@title\n","    # @ staticmethod\n","    # def on_char_input(change):\n","    #     def generate_random_response(prefix):\n","    #         length = random.randrange(10, 30)\n","    #         vocab = 'abcdefghijklmnopqrstuvwxyz '\n","    #         return prefix + ''.join(random.choice(vocab) for _ in range(length))\n","\n","    #     if ((change['type'] == 'change') and\n","    #         (change['name'] == 'value')):\n","\n","    #         widget = change['owner']\n","    #         prefix = widget.get_interact_value().lower()\n","    #         widget.options = [generate_random_response(prefix) for _ in range(3)]\n","    #         widget.options = [\"I want to order a pizza\", \"I want to order a large pepperoni pizza\"]\n","    #         # w.placeholder = w.options[0]\n","    #         widget.ensure_option = False\n","\n","from ipywidgets import CallbackDispatcher, register, Text\n","\n","from ipywidgets import trait_types \n","from traitlets import Unicode, Bool, Int, Container\n","\n","\n","@register\n","class Combobox(Text):\n","    \"\"\"Single line textbox widget with a dropdown and autocompletion.\n","    \"\"\"\n","    _model_name = Unicode('ComboboxModel').tag(sync=True)\n","    _view_name = Unicode('ComboboxView').tag(sync=True)\n","\n","    options = trait_types.TypedTuple(\n","        trait=Unicode(),\n","        help=\"Dropdown options for the combobox\"\n","    ).tag(sync=True)\n","\n","    ensure_option = Bool(\n","        False,\n","        help='If set, ensure value is in options. Implies continuous_update=False.'\n","    ).tag(sync=True)\n","\n","\n","#@title Interface Setup\n","import ipywidgets as widgets\n","from IPython.display import clear_output\n","import random\n","from functools import partial\n","\n","class TestingInterface():\n","    def __init__(self, model, **kwargs):\n","        self.model = model\n","        self.kwargs = kwargs\n","\n","        self.context_widget = widgets.Textarea(rows=1)\n","        self.context_widget.observe(self.on_context_changed)\n","\n","        self.history_widget = widgets.Textarea(\n","            placeholder='previous messages will appear here..',\n","            rows=10\n","        )\n","        self.history_widget.disabled = True\n","        self.reset_btn = widgets.Button(description='Reset')\n","        self.reset_btn.on_click(self.reset)\n","\n","        self.response_widget = Combobox(\n","            options=[], \n","            value=\"\", \n","            placeholder='Enter your message here', \n","            ensure_option=False, \n","            continuous_update=True,\n","            rows=3\n","        )\n","        self.response_widget.observe(\n","            self.on_char_input\n","        )\n","            # self.debouncer\n","        self.response_widget.on_submit(self.on_response_submission)\n","\n","        self.grid_placeholder = widgets.Label()\n","\n","        self.grid = [\n","            self.grid_placeholder, self.reset_btn, \n","            widgets.Label('Context:'), self.context_widget, \n","            widgets.Label('History:'), self.history_widget, \n","            widgets.Label('Response:'), self.response_widget, \n","        ]\n","\n","        self.layout_style = \"\"\"repeat(2, 100px)\"\"\"\n","\n","        self.ui = widgets.GridBox(\n","            self.grid, \n","            layout=widgets.Layout(grid_template_columns=self.layout_style)\n","        )\n","\n","        self.prev_speaker = \"Person2: \"\n","        self.last_call = time.time()\n","\n","    @property\n","    def current_speaker(self):\n","        if self.prev_speaker == 'Person2: ':\n","            self.prev_speaker = 'Person1: '\n","    \n","        else:\n","            self.prev_speaker = 'Person2: '\n","    \n","        return self.prev_speaker\n","    \n","    def debouncer(self, change):\n","        if ((change['type'] == 'change') and\n","            (change['name'] == 'value')):\n","\n","            elapsed = time.time() - self.last_call\n","            self.last_call = time.time()\n","\n","            if (elapsed) > 0.1:\n","                self.on_char_input(change)\n","\n","    def on_char_input(self, change):\n","        widget = change['owner']\n","        prefix = widget.get_interact_value().lower()\n","        if prefix and prefix[-1]!= \" \":\n","            return\n","        eos_token = self.model.tokenizer.eos_token\n","        options, scores = self.model.predict(\n","            \"compelete: \"\n","            + self.history_widget.value.replace(\"\\n\", eos_token)\n","            + eos_token\n","            + prefix,\n","            **self.kwargs,\n","        )\n","        # widget.options = [prefix + option for option in widget.options]\n","        # clear_output(wait=False)\n","        # self.display()\n","        # print()\n","        print(f'\\rSuggestion ({scores[0]:0.3f}):' + Fore.LIGHTGREEN_EX,\n","              options[0], \n","              end=Style.RESET_ALL, \n","              flush=True\n","        )\n","\n","        # w.placeholder = w.options[0]\n","        widget.ensure_option = False\n","\n","    def on_response_submission(self, widget):\n","        response = widget.value\n","        if response:\n","            widget.value = \"\"\n","            widget.options = []\n","            self.history_widget.value += \"\\n\" + self.current_speaker + response\n","            self.history_widget.value = self.history_widget.value.strip()\n","\n","    @staticmethod\n","    def on_context_changed(change):\n","        widget = change['owner']\n","        if ((change['type'] == 'change') and\n","            (change['name'] == 'value')):\n","            context_text = widget.get_interact_value()\n","            # print(context_text)\n","\n","    def reset(self, reset_btn):\n","        self.context_widget.value = ''\n","        self.history_widget.value = ''\n","        \n","        self.response_widget.value = ''\n","        self.response_widget.options = []\n","        \n","        clear_output(wait=True)\n","        self.display()\n","\n","    def display(self):\n","      display(self.ui)\n"],"metadata":{"id":"uKnAisJn3vVV","cellView":"form","executionInfo":{"status":"ok","timestamp":1657207335139,"user_tz":-120,"elapsed":23,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"tg1fipoE5EoH"}},{"cell_type":"markdown","source":["## Manual Testing"],"metadata":{"id":"VYq1azG16VtM"}},{"cell_type":"code","source":["#@title\n","from pprint import pprint\n","reset_environment()\n","LOCAL_DIR = \"T5 Checkpoints/\" \n","LOCAL_DIR =  PROJECT_PATH + LOCAL_DIR\n","\n","best_checkpoint_name = \"t5-v1_1-base_BatchSize-16_N-Splits-4_DatasetSize-large_Topic-Food&Drink_version_2\"\n","best_checkpoint_path = LOCAL_DIR+\"t5-v1_1-base_check_points/t5-v1_1-base_BatchSize-16_N-Splits-4_DatasetSize-large_Topic-Food&Drink/version_2/-epoch-9-tloss-1.5577-vloss-1.8296\"\n","\n","\n","best_checkpoint_name = \"t5-v1_1-base_BatchSize-16_N-Splits-4_DatasetSize-large_Topic-Food&Drink_version_2\"\n","best_checkpoint_path = LOCAL_DIR+\"-epoch-9-tloss-1.5577-vloss-1.8296\"\n","\n","\n","def get_model_from_disk(checkpoint_path, model_name, use_gpu=True):\n","    model = SimpleT5(model_name, output_dir=\"\", learning_rate=1e-4)\n","    model.load_model(checkpoint_path, use_gpu=use_gpu)\n","    return model\n","\n","top_model = get_model_from_disk(\n","    best_checkpoint_path, \n","    best_checkpoint_name, \n","    use_gpu=True)\n","\n","\n","kwargs = {\n","    \"num_return_sequences\": 3, \n","    \"num_beams\": 3, \n","    \"top_p\": 0.95,\n","    \"top_k\": 100,\n","    \"temperature\": 1.0 \n","}\n","\n","def get_suggestions(model, prompt, return_scores=False, kwargs=kwargs):\n","    suggestions, scores = model.predict(\"comeplete: \" + prompt, **kwargs)\n","    if return_scores:\n","        return suggestions, scores\n","\n","    print(\"\\n\".join(suggestions))"],"metadata":{"id":"2TV45Wko5qK2","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657207369577,"user_tz":-120,"elapsed":2308,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"e6e4a58a-b384-4999-bd8b-04c9e88b36b8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 512\n"]}]},{"cell_type":"markdown","source":["## Good Examples"],"metadata":{"id":"S9Q2EpBIjglS"}},{"cell_type":"code","source":["get_suggestions(top_model, \"I want to eat\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PRxzoLBG-Tid","executionInfo":{"status":"ok","timestamp":1657011000801,"user_tz":-120,"elapsed":392,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"3701705c-a789-4e6e-e805-cb607e417082"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a pizza with my family tonight.\n","a pizza.\n","a pizza with my friends.\n"]}]},{"cell_type":"code","source":["get_suggestions(top_model, \"I want to drink\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1ji7rvp-ch2","executionInfo":{"status":"ok","timestamp":1657011012722,"user_tz":-120,"elapsed":506,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"d5b1e1fc-665a-48a0-a2af-38c7133df0ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a cup of coffee.\n","a cup of coffee, please.\n","a cup of coffee. It tastes good.\n"]}]},{"cell_type":"code","source":["get_suggestions(top_model, \"I want to order a\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mxDtthMA-r9m","executionInfo":{"status":"ok","timestamp":1657011019768,"user_tz":-120,"elapsed":572,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"d120d4a7-f39f-4678-e191-8862fa193e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["burger for pickup at the local Burger King.\n","burger for pickup at the nearest Burger King.\n","burger for pickup at the local Burger King\n"]}]},{"cell_type":"code","source":["get_suggestions(top_model, \"May I order a\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqS6vQIZ-69j","executionInfo":{"status":"ok","timestamp":1657011031598,"user_tz":-120,"elapsed":513,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"af90427e-66f2-4d0d-ce46-3c40711fcffa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["iced coffee from starbucks\n","burger for me?\n","iced coffee from Starbucks\n"]}]},{"cell_type":"code","source":["get_suggestions(top_model, \"What kind of pizza toppings do you have?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUXDpzlx--8y","executionInfo":{"status":"ok","timestamp":1657011040377,"user_tz":-120,"elapsed":850,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"61258818-f846-43a0-8330-ecfcccd67418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a variety of pizza toppings. I've got pepperoni, sausage, bacon, and pineapple.\n","a variety of pizza toppings. I've got pepperoni, bacon, sausage, and pineapple.\n","a variety of pizza toppings. I've got pepperoni, sausage, and bacon.\n"]}]},{"cell_type":"code","source":["get_suggestions(top_model, \"I want to order a large pizza with\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbB7q8c9kJps","executionInfo":{"status":"ok","timestamp":1657011305805,"user_tz":-120,"elapsed":326,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"dc174512-368f-4a4d-a130-c2bb0f1cc179"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ham and pineapple\n","ham and pineapple on it\n","ham and pineapple.\n"]}]},{"cell_type":"code","source":["get_suggestions(top_model, \"I want to order a double cheese burger with\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDQr5lX5kRh1","executionInfo":{"status":"ok","timestamp":1657011307167,"user_tz":-120,"elapsed":199,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"e13f815e-63b4-44b9-b49c-99f8418d7c46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ketchup and onions\n","ketchup and mustard\n","ketchup and onions.\n"]}]},{"cell_type":"markdown","source":["## Bad Examples"],"metadata":{"id":"kZZCumBAhNAY"}},{"cell_type":"code","source":["bad_checkpoint_name = \"t5v1.1-base-small-dataset\"\n","bad_checkpoint_path = LOCAL_DIR+\"simplet5-epoch-9-train-loss-2.1007-val-loss-2.4144/\"\n","bad_model = get_model_from_disk(\n","    bad_checkpoint_path, \n","    bad_checkpoint_name, \n","    use_gpu=True\n",")"],"metadata":{"id":"dv1cJyK3krnS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reset_environment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVDDTxXElRVU","executionInfo":{"status":"ok","timestamp":1657011513542,"user_tz":-120,"elapsed":64,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"591e490f-633b-4121-e6e2-ef9dea3dbeae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 512\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"I want to eat\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvLDGquXhMo7","executionInfo":{"status":"ok","timestamp":1657011489447,"user_tz":-120,"elapsed":310,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"8c5f75b1-3180-4fd8-9a7a-336ef1b09792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["food in the centre of town.\n","food in San Francisco, California.\n","food in San Francisco.\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"I want to drink\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NSF35oUjlSy","executionInfo":{"status":"ok","timestamp":1657011493315,"user_tz":-120,"elapsed":313,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"c52c53f3-4228-4c41-f48c-5c8e213cc804"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a drink with my friends tonight.\n","drink a lot of coffee.\n","a drink.\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"I want to order a\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vB7zMzqMjpEt","executionInfo":{"status":"ok","timestamp":1657011498158,"user_tz":-120,"elapsed":447,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"892a4063-7531-43f7-d1f3-923028480003"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["restaurant in San Francisco, California.\n","restaurant that serves Mexican food in the centre of town\n","restaurant that serves Mexican food.\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"May I order a\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csavixcejqLt","executionInfo":{"status":"ok","timestamp":1657011517227,"user_tz":-120,"elapsed":647,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"4080e168-daa5-4eca-d82a-2cb6afa93c38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cab to take me from JFK International Airport to the nearest Starbucks?\n","cab to take me from JFK International Airport to the Hilton Hotel?\n","restaurant in San Francisco, California?\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"What kind of pizza toppings do you have?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTAHiH0ejq6q","executionInfo":{"status":"ok","timestamp":1657011521247,"user_tz":-120,"elapsed":382,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"1c17625c-4bb6-45ea-fe47-0bc7046cd4a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What kind of crust do you want?\n","What kind of crust?\n","I have pepperoni and sausage.\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"I want to order a large pizza with\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqYuWsxvlIio","executionInfo":{"status":"ok","timestamp":1657011523327,"user_tz":-120,"elapsed":382,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"03daaaac-2ce8-4515-e092-3052164d1366"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a side of french fries and pepperoni.\n","a side of french fries, please.\n","a side of french fries.\n"]}]},{"cell_type":"code","source":["get_suggestions(bad_model, \"I want to order a double cheese burger with\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2BzmpwklK06","executionInfo":{"status":"ok","timestamp":1657072183721,"user_tz":-120,"elapsed":8579,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"6f3d94da-879e-47b7-e930-febcb7165414"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a side of fries and french fries.\n","a side of fries and french fries, please.\n","a side of french fries and a side of fries.\n"]}]},{"cell_type":"markdown","source":["## Live Testing"],"metadata":{"id":"MsTWlcss6Z_U"}},{"cell_type":"code","source":["#@title # T5 Model inference { vertical-output: true, display-mode: \"form\" }\n","interface = TestingInterface(\n","    top_model,\n","    num_return_sequences=1, \n","    num_beams=3, \n","    top_k=100, \n","    top_p=0.94\n",")\n","\n","interface.display()\n","print(\"\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344,"referenced_widgets":["5b062a5f40e346ec9c81283367f834ff","ae9f2423cdf945febd842e0881c904eb","43bdafacc1c641c1954c18aa0c9f8fcf","85ee7d005e4e48f9ba2777a3fc261a29","36df6ed034fb430b86dc882ff789b8f3","1d04fad5b74d40968591f5f5d74c1b78","638cf2391d74456289a8d266c4d7cdc1","c64606327c314de889a5ceee8aaa96a7","01c56af383d1481898ee09de169cd341","1fc33ec8d9b14733a67620fe3d4d5c8d","a83f3f88fa0841b78c8377769e7e4e20","581f6d7a8c544ccca9d761eeb99a133e","a1de34802319471d9f492299865486b2","a8276aff44e54781aa8b0e5ba363368d","732338c3057d49e9ac0b644dded59cae","c616f2cdd614424fb6e807ee65783a8f","06d2137dab7d485da278f1b10cb16ad6","5cc5e69ce9a24f928ec1ba065c3de2e2","58ed4984875d4a35b5c193cd6bebeb08","67a9a61f64c04001abf09cf3214fd538","5339c6661ea44683a3e7213438080d26","93cd795979d34e11b7cf02ac486a2ffe","0dedb64e25b94ac1a24424f70adeefaa","379bcc8e6a2c4beebbd79138940c8590","8806babcff984d728047157678ab49ab","db896375761c49feb6dddd038a56524d"]},"id":"sG88gDqJQHlF","executionInfo":{"status":"ok","timestamp":1657207377726,"user_tz":-120,"elapsed":70,"user":{"displayName":"Mohamed Hisham","userId":"09704671302756774950"}},"outputId":"da20b2bd-a44c-4ff6-9d68-4cdaf4805908"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["GridBox(children=(Label(value=''), Button(description='Reset', style=ButtonStyle()), Label(value='Context:'), …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b062a5f40e346ec9c81283367f834ff"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Suggestion (-0.477):\u001b[92m 'm looking for a place to dine in the centre of town that serves italian food\u001b[0m"]}]}]}